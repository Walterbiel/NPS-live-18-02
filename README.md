# An√°lise NPS

Este projeto realiza uma an√°lise de Net Promoter Score (NPS) com base em dados coletados de clientes. Para mais detalhes sobre os requerimentos, consulte o arquivo **.pdf** dispon√≠vel no reposit√≥rio.

## Dicion√°rio de Dados

As perguntas e suas respectivas descri√ß√µes:

- **Q_um**: N√≠vel de satisfa√ß√£o com a empresa (live18)
- **Q_dois**: N√≠vel de satisfa√ß√£o com o tempo de entrega
- **Q_tres**: N√≠vel de satisfa√ß√£o com o tempo de resposta aos pedidos
- **Q_quatro**: N√≠vel de satisfa√ß√£o com o time de CX
- **Q_cinco**: N√≠vel de satisfa√ß√£o com a qualidade do produto
- **Q_seis**: N√≠vel de satisfa√ß√£o com a embalagem do produto
- **Q_sete**: N√≠vel de satisfa√ß√£o com o pre√ßo
- **Q_oito**: N√≠vel de satisfa√ß√£o com o aplicativo de status
- **Q_nove**: N√≠vel de satisfa√ß√£o com a plataforma de pedidos
- **Q_dez**: (Faltando descri√ß√£o, adicionar)

## C√°lculo do NPS

O NPS √© calculado com base nas respostas dos clientes e categorizado da seguinte forma:

- **Detratores**: Notas de **1 a 6**
- **Neutros**: Notas de **7 a 8**
- **Promotores**: Notas de **9 a 10**

F√≥rmula:

\[ NPS = \frac{\text{Promotores} - \text{Detratores}}{\text{N√∫mero total de respondentes}} \]

## Instala√ß√£o de Depend√™ncias

Para instalar os pacotes necess√°rios, execute:

```bash
pip install -r requirements.txt
```

## Banco de Dados

Para utilizar o PostgreSQL, voc√™ pode:

### 1. Subir o banco via Docker:
```bash
docker-compose up -d
```

### 2. Ou instalar o PostgreSQL manualmente.

## Execu√ß√£o da API

Para iniciar a API, execute:

```bash
uvicorn event_producer:app --reload --port 8080
```

## Chamadas √† API

### 1. Via HTTP (POST):

```plaintext
POST http://127.0.0.1:8080/gerar_dados/?num_rows=100
```

### 2. Via cURL:

```bash
curl -X 'POST' \
  'http://127.0.0.1:8080/gerar_dados/?num_rows=100' \
  -H 'accept: application/json'
```

## Documenta√ß√£o

Para acessar a documenta√ß√£o interativa da API (Swagger UI), acesse:

[http://127.0.0.1:8080/docs](http://127.0.0.1:8080/docs)



# üìä API FastAPI para Gera√ß√£o de Dados Fict√≠cios de NPS  

Este projeto implementa uma API utilizando **FastAPI** para gerar e armazenar dados fict√≠cios de feedback NPS em um banco de dados **PostgreSQL**, usando **SQLAlchemy** como ORM e **Faker** para gera√ß√£o de dados sint√©ticos.  

## üìå Tecnologias e Bibliotecas  

- **FastAPI** ‚Üí Framework para cria√ß√£o de APIs REST de alto desempenho.  
- **SQLAlchemy** ‚Üí ORM para defini√ß√£o do modelo de dados e intera√ß√£o com PostgreSQL.  
- **Faker** ‚Üí Biblioteca para gera√ß√£o de dados fict√≠cios realistas.  
- **NumPy** ‚Üí Gera√ß√£o de valores aleat√≥rios.  
- **Pandas** ‚Üí Estrutura√ß√£o e manipula√ß√£o de dados.  
- **Uvicorn** ‚Üí Servidor ASGI para execu√ß√£o da API.  
- **PostgreSQL (via Docker)** ‚Üí Banco de dados para persist√™ncia dos registros.  

## üìÇ Estrutura e Funcionamento  

### 1Ô∏è‚É£ **Configura√ß√£o da API**  

A API √© criada utilizando **FastAPI**, com a seguinte configura√ß√£o:  

```python
from fastapi import FastAPI

app = FastAPI()
```

Isso inicializa uma inst√¢ncia da aplica√ß√£o, permitindo a defini√ß√£o de rotas e endpoints.  

---

### 2Ô∏è‚É£ **Configura√ß√£o do Banco de Dados**  

A conex√£o com PostgreSQL √© definida usando **SQLAlchemy**, configurando usu√°rio, senha, host e porta:  

```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

DATABASE_URL = "postgresql://admin:admin123@localhost:5432/mydatabase"
engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
```

Aqui, `create_engine()` inicializa a conex√£o, enquanto `sessionmaker()` permite a cria√ß√£o de sess√µes transacionais.  

---

### 3Ô∏è‚É£ **Defini√ß√£o do Modelo de Dados**  

O modelo `NPSFeedback` √© definido como uma tabela SQLAlchemy, representando os campos necess√°rios para armazenar os feedbacks:  

```python
from sqlalchemy import Column, Integer, String, Date
from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()

class NPSFeedback(Base):
    __tablename__ = "nps_feedback"

    id = Column(Integer, primary_key=True, index=True)
    nome = Column(String)
    email = Column(String)
    idade = Column(Integer)
    genero = Column(String)
    cidade = Column(String)
    pais = Column(String)
    mercado = Column(String)
    data_resposta = Column(Date)
    Q_um = Column(Integer)
    Q_dois = Column(Integer)
    Q_tres = Column(Integer)
    Q_quatro = Column(Integer)
    Q_cinco = Column(Integer)
    Q_seis = Column(Integer)
    Q_sete = Column(Integer)
    Q_oito = Column(Integer)
    Q_nove = Column(Integer)
    Q_dez = Column(Integer)
```

A fun√ß√£o `Base.metadata.create_all(bind=engine)` cria a tabela no banco caso ainda n√£o exista.  

---

### 4Ô∏è‚É£ **Gera√ß√£o de Dados Fict√≠cios**  

Os dados fict√≠cios s√£o criados com **Faker** e **NumPy**, gerando informa√ß√µes aleat√≥rias para simular respostas de clientes:  

```python
from faker import Faker
import numpy as np

fake = Faker()

def generate_fake_data(num_rows=100):
    data = []
    for _ in range(num_rows):
        data.append({
            "nome": fake.name(),
            "idade": np.random.randint(18, 70),
            "genero": np.random.choice(["Masculino", "Feminino"]),
            "pais": fake.country(),
            "data_resposta": fake.date_this_year(),
            "mercado": np.random.choice([
                "Alimentos e Bebidas", "Tecnologia e Eletr√¥nicos", "Sa√∫de e Bem-Estar",
                "Moda e Vestu√°rio", "Automotivo", "Educa√ß√£o e Treinamento",
                "Constru√ß√£o e Imobili√°rio", "Entretenimento e M√≠dia", "Beleza e Cosm√©ticos", "Financeiro e Seguros"
            ]),
            "Q_um": np.random.randint(1, 10),
            "Q_dois": np.random.randint(1, 10),
            "Q_tres": np.random.randint(1, 10),
            "Q_quatro": np.random.randint(1, 10),
            "Q_cinco": np.random.randint(1, 10),
            "Q_seis": np.random.randint(1, 10),
            "Q_sete": np.random.randint(1, 10),
            "Q_oito": np.random.randint(1, 10),
            "Q_nove": np.random.randint(1, 10),
            "Q_dez": np.random.randint(1, 10)
        })
    return data
```

---

## üöÄ Como Rodar o Projeto  

### 1Ô∏è‚É£ Instalar Depend√™ncias  

```bash
pip install fastapi[all] pandas numpy faker sqlalchemy psycopg2
```

### 2Ô∏è‚É£ Configurar o PostgreSQL via Docker  

```bash
docker run --name postgres_nps -e POSTGRES_USER=admin -e POSTGRES_PASSWORD=admin123 -e POSTGRES_DB=mydatabase -p 5432:5432 -d postgres
```

### 3Ô∏è‚É£ Rodar a API  

```bash
uvicorn event_producer:app --reload --port 8080
```

### 4Ô∏è‚É£ Testar o Endpoint  

**Via requests:** 
```python
import requests

# URL da API
url = "http://127.0.0.1:8080/gerar_dados/"

# Par√¢metro num_rows
params = {"num_rows": 2000}

# Enviar a requisi√ß√£o POST
response = requests.post(url, params=params)

# Verificar a resposta da API
if response.status_code == 200:
    print("Dados gerados com sucesso!")
    print(response.json()) 
else:
    print(f"Erro ao gerar dados. Status Code: {response.status_code}")
    print(response.text)

```

**Via Swagger UI:**  
- Acesse: [http://localhost:8080/docs](http://localhost:8080/docs)  

**Via cURL:**  
```bash
curl -X 'POST' 'http://localhost:8080/gerar_dados/?num_rows=200' -H 'accept: application/json'
```

### 5Ô∏è‚É£ Consultar Dados no PostgreSQL  

```sql
SELECT * FROM nps_feedback;
```

---


### Criar view no postgres, via Bash: 
```bash
python sql_views.py
```

### Para rodar o streamlit:
```bash
streamlit run app.py
```

